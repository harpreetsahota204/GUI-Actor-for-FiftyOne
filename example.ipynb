{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSPH_2aycMCO"
      },
      "source": [
        "\n",
        "## 📋 Prerequisites:\n",
        "- **GPU Runtime**: Select GPU in `Runtime` → `Change runtime type`\n",
        "- **Hugging Face Account**: For accessing models and datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOu_2kKKmMqC"
      },
      "source": [
        "# 📦 Installation & Setup\n",
        "\n",
        "First, let's install all the required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYTY7i4vHH3K"
      },
      "outputs": [],
      "source": [
        "!pip install -q flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ2vj02kT2uk"
      },
      "outputs": [],
      "source": [
        "!pip install -e git+https://github.com/harpreetsahota204/GUI-Actor-for-FiftyOne.git#egg=gui_actor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "046FXiTJNZjh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import os\n",
        "import fiftyone as fo\n",
        "import fiftyone.utils.huggingface as fouh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY9JNWcxOGIX"
      },
      "source": [
        "## Load an SFT Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7FiO9ApBeqJ",
        "outputId": "687df413-0081-4381-856e-6a75dfe04f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading config file fiftyone.yml from harpreetsahota/FiftyOne-GUI-Grounding-Train\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.huggingface:Downloading config file fiftyone.yml from harpreetsahota/FiftyOne-GUI-Grounding-Train\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.huggingface:Loading dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Importing samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:fiftyone.utils.data.importers:Importing samples...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 739/739 [36.6ms elapsed, 0s remaining, 20.2K samples/s]     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 739/739 [36.6ms elapsed, 0s remaining, 20.2K samples/s]     \n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "dataset = load_from_hub(\n",
        "    \"harpreetsahota/FiftyOne-GUI-Grounding-Train\",\n",
        "    overwrite=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnKOB2OrS0yi",
        "outputId": "757f1878-ccb7-4175-ba58-124bb4e5b822"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Keypoint: {\n",
              "    'id': '68b1ad2fcd37ccc965b1dcf1',\n",
              "    'attributes': {},\n",
              "    'tags': [],\n",
              "    'label': 'click',\n",
              "    'points': [[0.5, 0.28627170617420067]],\n",
              "    'confidence': None,\n",
              "    'index': None,\n",
              "    'visible': [2],\n",
              "    'coco_id': 1,\n",
              "    'supercategory': 'interaction',\n",
              "    'iscrowd': 0,\n",
              "    'task_description': 'Open color settings',\n",
              "    'action_type': 'click',\n",
              "    'element_info': 'Icon',\n",
              "    'custom_metadata': {},\n",
              "}>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.first().keypoints.keypoints[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UgsFovHoMdSr"
      },
      "outputs": [],
      "source": [
        "KP_SYSTEM_MESSAGE = \"\"\"You are a GUI Agent specialized in interacting with the FiftyOne application. Given a screenshot of the current FiftyOne GUI and a human instruction, your task is to locate the screen element that corresponds to the instruction.\n",
        "\n",
        "You should output a response indicating the element type to interact with, action to be taken on that element, correct position of the action, and any additional metadata.\n",
        "\n",
        "Your response must be a valid JSON wrapped exactly this format:\n",
        "\n",
        "```json\n",
        "{{\"element_info\": {element_info}, \"label\": \"{label}\", \"points\": {points}, \"custom_metadata\": {custom_metadata}}}\n",
        "```\"\"\"\n",
        "\n",
        "BB_SYSTEM_MESSAGE = \"\"\"You are a GUI Agent specialized in interacting with the FiftyOne application. Given a screenshot of the current FiftyOne GUI and a human instruction, your task is to locate the screen element that corresponds to the instruction.\n",
        "\n",
        "You should output a response indicating the element type to interact with, action to be taken on that element, correct position of the action, and any additional metadata.\n",
        "\n",
        "Your response must be a valid JSON wrapped exactly this format:\n",
        "\n",
        "```json\n",
        "{{\"element_info\": {element_info}, \"label\": \"{label}\", \"bounding_box\": {bounding_box}, \"custom_metadata\": {custom_metadata}}}\n",
        "```\"\"\"\n",
        "\n",
        "\n",
        "def add_message_payload_to_dataset(dataset):\n",
        "    \"\"\"\n",
        "    Add message payload to all keypoints and detections, where the label\n",
        "    represents the ACTION to be performed (click, type, select, etc.).\n",
        "\n",
        "    Converts bounding boxes from [x, y, width, height] to [x_min, y_min, x_max, y_max] for bbox_gt.\n",
        "    \"\"\"\n",
        "\n",
        "    for sample in dataset.iter_samples(autosave=True, progress=True):\n",
        "        filepath = sample[\"filepath\"]\n",
        "\n",
        "        # Process keypoints (point-based interactions)\n",
        "        if sample.keypoints:\n",
        "            for kp in sample.keypoints.keypoints:\n",
        "                # Extract keypoint attributes\n",
        "                task_desc = getattr(kp, 'task_description', '')\n",
        "                element_info = getattr(kp, 'element_info', {})\n",
        "                action = getattr(kp, 'label', '')\n",
        "                points = getattr(kp, 'points', [])\n",
        "                custom_metadata = getattr(kp, 'custom_metadata', {})\n",
        "\n",
        "                # Extract coordinates for pointer loss\n",
        "                if points and len(points) > 0:\n",
        "                    x, y = points[0]\n",
        "\n",
        "                    # Create response with action and location\n",
        "                    response_text = f\"\"\"I can {action} the {element_info} at x={x}, y={y} to complete this task. Here is the valid JSON response: ```json {{\"action\": \"{action}\", \"element_info\": {element_info}, \"points\": {points}, \"custom_metadata\": {custom_metadata}}}```\"\"\"\n",
        "\n",
        "                    # Create message payload in the correct format\n",
        "                    messages = [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"text\", \"text\": KP_SYSTEM_MESSAGE}\n",
        "                            ]\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"image\", \"image\": filepath},\n",
        "                                {\"type\": \"text\", \"text\": task_desc}\n",
        "                            ]\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"assistant\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"text\", \"text\": response_text}\n",
        "                            ],\n",
        "                            \"recipient\": \"os\",\n",
        "                            \"end_turn\": True,\n",
        "                            \"point_gt\": points[0] if points else None\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "                    kp.message_payload = messages\n",
        "\n",
        "        # Process detections (region-based interactions)\n",
        "        if sample.detections:\n",
        "            for det in sample.detections.detections:\n",
        "                # Extract detection attributes\n",
        "                task_desc = getattr(det, 'task_description', '')\n",
        "                element_info = getattr(det, 'element_info', '')\n",
        "                action = getattr(det, 'label', '')\n",
        "                bounding_box = getattr(det, 'bounding_box', [])\n",
        "                custom_metadata = getattr(det, 'custom_metadata', {})\n",
        "\n",
        "                if bounding_box and len(bounding_box) == 4:\n",
        "                    # Extract bounding box coordinates [x, y, width, height]\n",
        "                    x, y, width, height = bounding_box\n",
        "\n",
        "                    # Convert to [x_min, y_min, x_max, y_max] format for bbox_gt\n",
        "                    x_min = x\n",
        "                    y_min = y\n",
        "                    x_max = x + width\n",
        "                    y_max = y + height\n",
        "                    bbox_gt_format = [x_min, y_min, x_max, y_max]\n",
        "\n",
        "                    # Create response with action and bounding box information\n",
        "                    response_text = f\"\"\"I can {action} the {element_info} from_coord=[{x_min}, {y_min}] to_coord=[{x_max}, {y_max}] to complete this task. Here is the valid JSON response: ```json {{\"action\": \"{action}\", \"element_info\": {element_info}, \"bounding_box\": {bbox_gt_format}, \"custom_metadata\": {custom_metadata}}}```\"\"\"\n",
        "\n",
        "                    # Create message payload in the correct format\n",
        "                    messages = [\n",
        "                        {\n",
        "                            \"role\": \"system\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"text\", \"text\": BB_SYSTEM_MESSAGE}\n",
        "                            ]\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"user\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"image\", \"image\": filepath},\n",
        "                                {\"type\": \"text\", \"text\": task_desc}\n",
        "                            ]\n",
        "                        },\n",
        "                        {\n",
        "                            \"role\": \"assistant\",\n",
        "                            \"content\": [\n",
        "                                {\"type\": \"text\", \"text\": response_text}\n",
        "                            ],\n",
        "                            \"recipient\": \"os\",\n",
        "                            \"end_turn\": True,\n",
        "                            \"bbox_gt\": bbox_gt_format\n",
        "                        }\n",
        "                    ]\n",
        "\n",
        "                    det.message_payload = messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFbeo6sT-loM",
        "outputId": "be3957a0-1b7e-454a-c985-144e4bc15cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████████| 739/739 [5.7s elapsed, 0s remaining, 198.9 samples/s]      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 739/739 [5.7s elapsed, 0s remaining, 198.9 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "add_message_payload_to_dataset(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2WXK7c2TAaE",
        "outputId": "b7badca6-5768-4f6b-d8d9-4afc13d37183"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Keypoint: {\n",
              "    'id': '68b1ad2fcd37ccc965b1dcf1',\n",
              "    'attributes': {},\n",
              "    'tags': [],\n",
              "    'label': 'click',\n",
              "    'points': [[0.5, 0.28627170617420067]],\n",
              "    'confidence': None,\n",
              "    'index': None,\n",
              "    'visible': [2],\n",
              "    'coco_id': 1,\n",
              "    'supercategory': 'interaction',\n",
              "    'iscrowd': 0,\n",
              "    'task_description': 'Open color settings',\n",
              "    'action_type': 'click',\n",
              "    'element_info': 'Icon',\n",
              "    'custom_metadata': {},\n",
              "    'message_payload': [\n",
              "        {\n",
              "            'role': 'system',\n",
              "            'content': [\n",
              "                {\n",
              "                    'type': 'text',\n",
              "                    'text': 'You are a GUI Agent specialized in interacting with the FiftyOne application. Given a screenshot of the current FiftyOne GUI and a human instruction, your task is to locate the screen element that corresponds to the instruction.\\n\\nYou should output a response indicating the element type to interact with, action to be taken on that element, correct position of the action, and any additional metadata.\\n\\nYour response must be a valid JSON wrapped exactly this format:\\n\\n```json\\n{{\"element_info\": {element_info}, \"label\": \"{label}\", \"points\": {points}, \"custom_metadata\": {custom_metadata}}}\\n```',\n",
              "                },\n",
              "            ],\n",
              "        },\n",
              "        {\n",
              "            'role': 'user',\n",
              "            'content': [\n",
              "                {\n",
              "                    'type': 'image',\n",
              "                    'image': '/root/fiftyone/huggingface/hub/harpreetsahota/FiftyOne-GUI-Grounding-Train/data/2025-07-22_18-23-08.png',\n",
              "                },\n",
              "                {'type': 'text', 'text': 'Open color settings'},\n",
              "            ],\n",
              "        },\n",
              "        {\n",
              "            'role': 'assistant',\n",
              "            'content': [\n",
              "                {\n",
              "                    'type': 'text',\n",
              "                    'text': 'I can click the Icon at x=0.5, y=0.28627170617420067 to complete this task. Here is the valid JSON response: ```json {\"action\": \"click\", \"element_info\": Icon, \"points\": [[0.5, 0.28627170617420067]], \"custom_metadata\": {}}```',\n",
              "                },\n",
              "            ],\n",
              "            'recipient': 'os',\n",
              "            'end_turn': True,\n",
              "            'point_gt': [0.5, 0.28627170617420067],\n",
              "        },\n",
              "    ],\n",
              "}>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.first().keypoints.keypoints[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUcuxPgnS-wF"
      },
      "source": [
        "# Split the dataset into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FAFM9SuTE0Wv"
      },
      "outputs": [],
      "source": [
        "import fiftyone.utils.random as four\n",
        "\n",
        "four.random_split(dataset, {\"train\": 0.8, \"val\": 0.2})\n",
        "\n",
        "train_view = dataset.match_tags(\"train\")\n",
        "\n",
        "val_view = dataset.match_tags(\"val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr2GaOyLTFS4"
      },
      "source": [
        "# Create PyTorch Datasets from the FiftyOne Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SEDFe2hCpCMR"
      },
      "outputs": [],
      "source": [
        "from fiftyone.utils.torch import GetItem\n",
        "\n",
        "class DataGetter(GetItem):\n",
        "    @property\n",
        "    def required_keys(self):\n",
        "        return ['filepath', 'keypoints', 'detections']\n",
        "\n",
        "    def __call__(self, d):\n",
        "        message_payloads = []\n",
        "\n",
        "        # Extract message_payload from all keypoints in the sample\n",
        "        keypoints = d.get(\"keypoints\")\n",
        "        if keypoints is not None and hasattr(keypoints, 'keypoints'):\n",
        "            for keypoint in keypoints.keypoints:\n",
        "                if hasattr(keypoint, 'message_payload') and keypoint.message_payload is not None:\n",
        "                    message_payloads.append(keypoint.message_payload)\n",
        "\n",
        "        # Extract message_payload from all detections in the sample\n",
        "        detections = d.get(\"detections\")\n",
        "        if detections is not None and hasattr(detections, 'detections'):\n",
        "            for detection in detections.detections:\n",
        "                if hasattr(detection, 'message_payload') and detection.message_payload is not None:\n",
        "                    message_payloads.append(detection.message_payload)\n",
        "\n",
        "        return {\n",
        "            \"filepath\": d.get(\"filepath\", \"\"),\n",
        "            \"message_payload\": message_payloads,\n",
        "        }\n",
        "\n",
        "\n",
        "class FlattenedDataset:\n",
        "    \"\"\"\n",
        "    Flattens a FiftyOne torch dataset so each item is a single message_payload\n",
        "    with its associated filepath.\n",
        "    \"\"\"\n",
        "    def __init__(self, fiftyone_torch_dataset):\n",
        "        self.items = []\n",
        "        for sample in fiftyone_torch_dataset:\n",
        "            filepath = sample[\"filepath\"]\n",
        "            for message_payload in sample[\"message_payload\"]:\n",
        "                if message_payload:  # Only add non-empty payloads\n",
        "                    self.items.append({\n",
        "                        \"filepath\": filepath,\n",
        "                        \"message_payload\": message_payload\n",
        "                    })\n",
        "        print(f\"FlattenedDataset created with {len(self.items)} items\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.items[idx]\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGJ7yr4OGll5",
        "outputId": "ebc37545-2949-42d2-f667-3a0ae46e235d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FlattenedDataset created with 2628 items\n",
            "FlattenedDataset created with 939 items\n"
          ]
        }
      ],
      "source": [
        "# Create torch datasets using DataGetter\n",
        "train_torch_dataset = train_view.to_torch(DataGetter())\n",
        "val_torch_dataset = val_view.to_torch(DataGetter())\n",
        "\n",
        "\n",
        "train_dataset = FlattenedDataset(train_torch_dataset)\n",
        "val_dataset = FlattenedDataset(val_torch_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZWJLmbRWRi2"
      },
      "source": [
        "# 🎯 GUI-Actor Fine-Tuning Recipe Report\n",
        "\n",
        "## 📋 **Executive Summary**\n",
        "\n",
        "The fine-tuning strategy for GUI-Actor on FiftyOne datasets has two distinct modes:\n",
        "\n",
        "1. **General Fine-tuning** (for multi-application scenarios)\n",
        "\n",
        "\n",
        "```python\n",
        "# Optimized for generalization across multiple applications\n",
        "num_train_epochs=3\n",
        "learning_rate=2e-5\n",
        "gradient_accumulation_steps=4\n",
        "warmup_ratio=0.1\n",
        "weight_decay=0.01\n",
        "unfreeze_all_parameters=False\n",
        "```\n",
        "\n",
        "2. **Single-Application Mode** (for specialized use cases). The implementation provides flexible parameter unfreezing strategies optimized for different training objectives.\n",
        "\n",
        "```python\n",
        "# Aggressive specialization for one target application\n",
        "single_app_mode=True  # Auto-configures aggressive settings\n",
        "unfreeze_vision_layers=True (auto-enabled)\n",
        "unfreeze_last_n_layers=8+ (auto-increased)\n",
        "# Allows intentional overfitting for maximum specialization\n",
        "```\n",
        "\n",
        "## 🧠 **Parameter Unfreezing Strategy**\n",
        "\n",
        "### **Layer-wise Unfreezing Hierarchy:**\n",
        "\n",
        "| Component | Default Mode | Single-App Mode | Rationale |\n",
        "|-----------|--------------|-----------------|-----------|\n",
        "| **Vision Layers** | ❌ Frozen | ✅ Last 25% unfrozen | Single-app needs visual specialization |\n",
        "| **Language Layers** | ✅ Last 4 unfrozen | ✅ Last 8+ unfrozen | Task-specific reasoning adaptation |\n",
        "| **LM Head** | ✅ Always unfrozen | ✅ Always unfrozen | Output vocabulary adaptation |\n",
        "| **Pointer Head** | ✅ Always unfrozen | ✅ Always unfrozen | Coordinate prediction adaptation |\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 **Training Hyperparameters**\n",
        "\n",
        "### **Learning Rate Strategy**\n",
        "\n",
        "- **Base LR**: `2e-5` (higher than original `5e-6` for better fine-tuning)\n",
        "- **Warmup**: `10%` of total steps (vs original `3%`)\n",
        "- **Scheduler**: Cosine decay for smooth convergence\n",
        "- **Weight Decay**: `0.01` for regularization (vs original `0.0`)\n",
        "\n",
        "### **Batch Configuration**\n",
        "- **Train Batch Size**: `1` per device (memory optimized)\n",
        "- **Eval Batch Size**: `4` per device (faster evaluation)\n",
        "- **Gradient Accumulation**: `4` steps (effective batch size = 4)\n",
        "- **Workers**: `4` (reduced from `8` for stability)\n",
        "\n",
        "### **Training Duration**\n",
        "- **Epochs**: `3` (vs original `1`) for better convergence\n",
        "- **Save Frequency**: Every `500` steps (vs original `2000`)\n",
        "- **Evaluation**: Enabled with validation set monitoring\n",
        "\n",
        "\n",
        "\n",
        "##  **Usage Recommendations**\n",
        "\n",
        "### **For General Fine-tuning** (Multi-application)\n",
        "```bash\n",
        "python train.py --dataset_name your_dataset\n",
        "# Uses conservative unfreezing, good generalization\n",
        "```\n",
        "\n",
        "### **For Single-Application Specialization**\n",
        "```bash\n",
        "python train.py --dataset_name your_app_data --single_app_mode\n",
        "# Aggressive unfreezing, maximum specialization\n",
        "```\n",
        "\n",
        "### **For Conservative Fine-tuning** (Small datasets)\n",
        "```bash\n",
        "python train.py --dataset_name small_dataset --unfreeze_last_n_layers 2\n",
        "# Minimal unfreezing, prevents overfitting\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839,
          "referenced_widgets": [
            "7f64e48d3c87439d95b7fbd47ce73753",
            "2b65be8a168744aba3e3364e73d27aa6",
            "a0e22393649d4c9aaaa610baaf5958e0",
            "e1edd12f4f5d4f41bcaeac5c8a054186",
            "577c25848797491695cc490b7165cc27",
            "b4b767e61a4d4777805dcf6be1559271",
            "87bf5c310312431e80393d822d47cee9",
            "bcb2214c222e4860a2146b13e4d5ea13",
            "f93cc43d54a34bcebef19836a850ce26",
            "c3613992d00843648bbaf187870abe3e",
            "775d42c17e034871b9273b8012b2b1f3"
          ]
        },
        "id": "usY22fFpdZ-d",
        "outputId": "61e82227-7a7c-4db4-cf89-19f445e2ca91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing CUDA memory allocation strategy...\n",
            "Memory optimization settings applied\n",
            "\n",
            "🚀 Starting GUI-Actor training with memory-optimized settings\n",
            "💾 Memory optimization techniques applied:\n",
            "  - Chunked tensor operations in forward pass\n",
            "  - Gradient checkpointing enabled\n",
            "  - PyTorch memory allocation optimized with expandable_segments\n",
            "  - Reduced sequence and image dimensions\n",
            "  - Increased gradient accumulation steps\n",
            "  - Using batch size: 1 with 16x accumulation\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f64e48d3c87439d95b7fbd47ce73753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
            "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 SINGLE-APP MODE: Applying aggressive fine-tuning settings...\n",
            "   - Vision layers will be unfrozen\n",
            "   - Unfreezing 8 transformer layers\n",
            "   - This will maximize adaptation to your specific application\n",
            "Using selective unfreezing strategy for fine-tuning...\n",
            "Unfreezing language modeling head...\n",
            "Unfreezing last 8 transformer layers...\n",
            "Unfreezing vision layers for single-application adaptation...\n",
            "  - Unfreezing Qwen2.5-VL vision blocks...\n",
            "    Unfroze last 8/32 vision blocks\n",
            "✓ Gradient checkpointing enabled for memory efficiency\n",
            "\n",
            "Trainable parameters: 1,084,853,696 (28.64%)\n",
            "Total parameters: 3,787,653,120\n",
            "\n",
            "GPU Memory Stats:\n",
            "  GPU 0: NVIDIA A100-SXM4-40GB\n",
            "    - Allocated: 7.06 GB\n",
            "    - Reserved: 7.13 GB\n",
            "    - Max Allocated: 7.06 GB\n",
            "\n",
            "Trainable components:\n",
            "- Language modeling head\n",
            "- Transformer layers: 28, 29, 30, 31, 32, 33, 34, 35\n",
            "[2025-08-29 14:52:17,185] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2025-08-29 14:52:19,256] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='126' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [126/165 49:15 < 15:29, 0.04 it/s, Epoch 0.76/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from gui_actor.train import train_gui_actor_on_fiftyone\n",
        "\n",
        "# Train the model\n",
        "model, processor = train_gui_actor_on_fiftyone(\n",
        "    train_dataset=train_dataset,\n",
        "    val_dataset=val_dataset,\n",
        "    num_train_epochs=1,\n",
        "    single_app_mode=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geui7WnBGaNX"
      },
      "outputs": [],
      "source": [
        "# One-liner to push to HF Hub (replace with your repo name)\n",
        "model.push_to_hub(\"gui-actor-fiftyone-finetuned\", private=True)\n",
        "processor.push_to_hub(\"gui-actor-fiftyone-finetuned\", private=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b65be8a168744aba3e3364e73d27aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4b767e61a4d4777805dcf6be1559271",
            "placeholder": "​",
            "style": "IPY_MODEL_87bf5c310312431e80393d822d47cee9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "577c25848797491695cc490b7165cc27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "775d42c17e034871b9273b8012b2b1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f64e48d3c87439d95b7fbd47ce73753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b65be8a168744aba3e3364e73d27aa6",
              "IPY_MODEL_a0e22393649d4c9aaaa610baaf5958e0",
              "IPY_MODEL_e1edd12f4f5d4f41bcaeac5c8a054186"
            ],
            "layout": "IPY_MODEL_577c25848797491695cc490b7165cc27"
          }
        },
        "87bf5c310312431e80393d822d47cee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e22393649d4c9aaaa610baaf5958e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcb2214c222e4860a2146b13e4d5ea13",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f93cc43d54a34bcebef19836a850ce26",
            "value": 2
          }
        },
        "b4b767e61a4d4777805dcf6be1559271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb2214c222e4860a2146b13e4d5ea13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3613992d00843648bbaf187870abe3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1edd12f4f5d4f41bcaeac5c8a054186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3613992d00843648bbaf187870abe3e",
            "placeholder": "​",
            "style": "IPY_MODEL_775d42c17e034871b9273b8012b2b1f3",
            "value": " 2/2 [00:02&lt;00:00,  1.29s/it]"
          }
        },
        "f93cc43d54a34bcebef19836a850ce26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
